{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b735ad3-fefc-4c97-be11-6e2b4381f746",
   "metadata": {},
   "source": [
    "# [Sample] Model management /Test automation in part of ML Ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4895cff7-5a01-4641-9b44-95db8f8c7c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from google.cloud import aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cab6d942-934f-4411-ac4b-4d2fba8ce4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameter\n",
    "num_epochs = 10         \n",
    "num_batch = 100         \n",
    "learning_rate = 0.001   \n",
    "image_size = 28*28\n",
    "\n",
    "# GPU(CUDA)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cdd30d3-dccc-4e1d-806f-f4998f1623b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timestamp Function\n",
    "from datetime import datetime\n",
    "def get_timestamp():\n",
    "    return datetime.now().strftime(\"%Y%m%d%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e3cefa-a434-48f6-86d7-fa5c3cf1f3bd",
   "metadata": {},
   "source": [
    "## Create Dataset for Train/Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "028b4534-aea4-4c9c-b537-1a41a97a7dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54a1c630-7423-4334-94f1-25a0b90685c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448265233/work/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "# For train\n",
    "train_dataset = datasets.MNIST(\n",
    "    './data',           \n",
    "    train = True,        \n",
    "    download = True,   \n",
    "    transform = transform\n",
    "    )\n",
    "# For eval\n",
    "test_dataset = datasets.MNIST(\n",
    "    './data', \n",
    "    train = False,\n",
    "    transform = transform\n",
    "    )\n",
    "\n",
    "# Data Loader\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size = num_batch,\n",
    "    shuffle = True)\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset,     \n",
    "    batch_size = num_batch,\n",
    "    shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5bdd36-a2f2-4dc1-844c-65fd2a4908f9",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "573cbea7-0e01-4dc2-9c95-bf9cc464054a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define NN\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(input_size, 100)\n",
    "        self.fc2 = nn.Linear(100, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Generate\n",
    "model = Net(image_size, 10).to(device)\n",
    "\n",
    "# Loss Func\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ad8f738-b55d-4472-adcf-2cb0516021ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10, Loss: 0.6680443318684895\n",
      "Epoch: 2/10, Loss: 0.26977516174316407\n",
      "Epoch: 3/10, Loss: 0.21305072784423829\n",
      "Epoch: 4/10, Loss: 0.1789398956298828\n",
      "Epoch: 5/10, Loss: 0.15450818379720052\n",
      "Epoch: 6/10, Loss: 0.1344214630126953\n",
      "Epoch: 7/10, Loss: 0.11916908264160156\n",
      "Epoch: 8/10, Loss: 0.10646553039550781\n",
      "Epoch: 9/10, Loss: 0.09521687825520833\n",
      "Epoch: 10/10, Loss: 0.08577755610148112\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "model.train() \n",
    "\n",
    "for epoch in range(num_epochs): \n",
    "    loss_sum = 0\n",
    "\n",
    "    for inputs, labels in train_dataloader:\n",
    "\n",
    "        # GPU\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # optimizer\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # NN Process\n",
    "        inputs = inputs.view(-1, image_size) # 画像データ部分を一次元へ並び変える\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss_sum += loss\n",
    "\n",
    "        # Gradient\n",
    "        loss.backward()\n",
    "\n",
    "        # Waight\n",
    "        optimizer.step()\n",
    "\n",
    "    # Display learning status\n",
    "    print(f\"Epoch: {epoch+1}/{num_epochs}, Loss: {loss_sum.item() / len(train_dataloader)}\")\n",
    "\n",
    "    # Save model waight\n",
    "    torch.save(model.state_dict(), 'model_weights.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc738bc3-02d7-44c4-af8c-0e2799b48222",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c54c8950-a48d-48a3-8e6e-a098bd90a668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.10480978012084961, Accuracy: 96.71% (9671/10000)\n"
     ]
    }
   ],
   "source": [
    "# Eval\n",
    "model.eval()\n",
    "\n",
    "loss_sum = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_dataloader:\n",
    "\n",
    "        # GPU\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # NN\n",
    "        inputs = inputs.view(-1, image_size)\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Loss\n",
    "        loss_sum += criterion(outputs, labels)\n",
    "\n",
    "        # Count number of correct\n",
    "        pred = outputs.argmax(1)\n",
    "        correct += pred.eq(labels.view_as(pred)).sum().item()\n",
    "\n",
    "print(f\"Loss: {loss_sum.item() / len(test_dataloader)}, Accuracy: {100*correct/len(test_dataset)}% ({correct}/{len(test_dataset)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ae9b7c-6d4b-42a8-b185-ef050a0f16c6",
   "metadata": {},
   "source": [
    "## Save Model as Pickl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3ad3646-fd02-4743-9f55-2dea9d81ef7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTAMP = 20230317091445\n"
     ]
    }
   ],
   "source": [
    "# Get Model timestamp\n",
    "TIMESTAMP = get_timestamp()\n",
    "print(f\"TIMESTAMP = {TIMESTAMP}\")\n",
    "!mkdir -p models/$TIMESTAMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "223d3ca8-5807-4e58-8161-e351e8fa06d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cloudpickle\n",
    "MODEL_PATH = 'models/'+TIMESTAMP+'/model.pkl'\n",
    "with open(MODEL_PATH, mode='wb') as f:\n",
    "    cloudpickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf220d8a-4ed1-4bea-b3c5-7f2277838177",
   "metadata": {},
   "source": [
    "## Upload the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96dcffc-797a-41eb-ab40-f014a7e28620",
   "metadata": {},
   "source": [
    "### Set Google Cloud environment variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d9e48bc-83f8-4a6f-b7c6-818039b7f1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### EDIT HERE ###\n",
    "PROJECT_ID = 'mlops-pipeline-demo'\n",
    "BUCKET_NAME = 'keihoshino-mlops-test-bucket'\n",
    "LOCATION = 'us-central1'\n",
    "\n",
    "MODEL_NAME = \"upload-test-model-khoshino\"\n",
    "SERVING_CONTAINER_IMAGE_URI = \"us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.1-0:latest\"\n",
    "VERSION_DESCRIPTION = \"\"\"\n",
    "This is my first model.\n",
    "\"\"\"\n",
    "#################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6f8c67-d441-4427-9756-cec6f4852dbf",
   "metadata": {},
   "source": [
    "### Upload the model to Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b13127a5-6666-43e0-af5e-a021550ad972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "\u001b[1;33mWARNING:\u001b[0m You do not appear to have access to project [mlops-pipeline-demo] or it does not exist.\n"
     ]
    }
   ],
   "source": [
    "!gcloud config set project $PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70a269e4-6029-4421-a723-a98e348e22b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://keihoshino-mlops-test-bucket/models/\n",
      "Bucket Already Exist\n"
     ]
    }
   ],
   "source": [
    "# Create Bucket if not exist\n",
    "import subprocess\n",
    "import sys\n",
    "s=subprocess.run([\"gsutil\",\"ls\",\"gs://\"+BUCKET_NAME])\n",
    "if s.returncode == 0:\n",
    "    print('Bucket Already Exist', file=sys.stdout)\n",
    "else:\n",
    "    !gsutil mb gs://$BUCKET_NAME\n",
    "    print('Bucket Created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8845c14a-6a3b-49e3-92e0-06237ea306a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://models/20230317091445/model.pkl [Content-Type=application/octet-stream]...\n",
      "/ [1 files][313.5 KiB/313.5 KiB]                                                \n",
      "Operation completed over 1 objects/313.5 KiB.                                    \n"
     ]
    }
   ],
   "source": [
    "ARTIFACT_URI = f'gs://{BUCKET_NAME}/models/{TIMESTAMP}'\n",
    "!gsutil cp $MODEL_PATH $ARTIFACT_URI/model.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41d9bed8-4339-475d-b569-99cbf33877c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Model\n",
      "Create Model backing LRO: projects/485539447870/locations/us-central1/models/4364676333200998400/operations/2357328534537502720\n",
      "Model created. Resource name: projects/485539447870/locations/us-central1/models/4364676333200998400@1\n",
      "To use this Model in another session:\n",
      "model = aiplatform.Model('projects/485539447870/locations/us-central1/models/4364676333200998400@1')\n",
      "<google.cloud.aiplatform.models.Model object at 0x7f3dbc07b650> \n",
      "resource name: projects/485539447870/locations/us-central1/models/4364676333200998400\n"
     ]
    }
   ],
   "source": [
    "# Upload the model to Model Registry\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)\n",
    "model = aiplatform.Model.upload(\n",
    "    display_name=MODEL_NAME,\n",
    "    artifact_uri=ARTIFACT_URI,\n",
    "    serving_container_image_uri=SERVING_CONTAINER_IMAGE_URI,\n",
    "    version_description=VERSION_DESCRIPTION,\n",
    ")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2d3e0a-208e-4c34-9153-27ab996f191e",
   "metadata": {},
   "source": [
    "### Get Model ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8fd668e7-1709-415d-b5f7-44f30db98fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
      "4364676333200998400  upload-test-model-khoshino\n"
     ]
    }
   ],
   "source": [
    "!gcloud ai models list --project=$PROJECT_ID --region=$LOCATION |grep $MODEL_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70c8e61-89f3-483c-a7af-65da16b947fe",
   "metadata": {},
   "source": [
    "## Upload New version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23d3b13f-d5be-4518-8d97-597faa7bcf61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20230317092101\n"
     ]
    }
   ],
   "source": [
    "MODEL_ID='4364676333200998400' # Get in previous step\n",
    "\n",
    "# Timestamp of new model\n",
    "TIMESTAMP = get_timestamp()\n",
    "print(TIMESTAMP)\n",
    "\n",
    "NEW_MODEL_PATH = 'models/'+TIMESTAMP+'/model.pkl'\n",
    "ARTIFACT_URI = f'gs://{BUCKET_NAME}/models/{TIMESTAMP}'\n",
    "VERSION_DESCRIPTION = \"\"\"\n",
    "This is New model. Tuned hyper parameters as .......\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "481a63fe-60b8-4494-9402-71ce6c20793b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習省略のため、既存のモデルをコピーしてタイムスタンプだけ変更\n",
    "!mkdir -p models/$TIMESTAMP\n",
    "!cp -ip $MODEL_PATH $NEW_MODEL_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0f7047b-3b75-4c21-be80-b42405f49045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://models/20230317092101/model.pkl [Content-Type=application/octet-stream]...\n",
      "/ [1 files][313.5 KiB/313.5 KiB]                                                \n",
      "Operation completed over 1 objects/313.5 KiB.                                    \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp $NEW_MODEL_PATH $ARTIFACT_URI/model.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ff6e6303-3518-46a7-973c-10e312d49913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Model\n",
      "Create Model backing LRO: projects/485539447870/locations/us-central1/models/4364676333200998400/operations/7610777499865186304\n",
      "Model created. Resource name: projects/485539447870/locations/us-central1/models/4364676333200998400@4\n",
      "To use this Model in another session:\n",
      "model = aiplatform.Model('projects/485539447870/locations/us-central1/models/4364676333200998400@4')\n"
     ]
    }
   ],
   "source": [
    "model = aiplatform.Model.upload(\n",
    "    parent_model=MODEL_ID,\n",
    "    artifact_uri=ARTIFACT_URI,\n",
    "    serving_container_image_uri=SERVING_CONTAINER_IMAGE_URI,\n",
    "    version_description=VERSION_DESCRIPTION,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0ea4cd-37c5-47a1-8564-87d411a6da11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-9.m82",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-9:m82"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
